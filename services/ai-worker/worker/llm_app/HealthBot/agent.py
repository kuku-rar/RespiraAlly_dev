import hashlib
import json
import os
import time
from typing import Any, Dict, List, Optional
from datetime import datetime

from crewai import LLM, Agent, Crew, Process, Task
from langchain_openai import ChatOpenAI
from openai import OpenAI

# ---- å°ˆæ¡ˆæ¨¡çµ„ï¼ˆæ³¨æ„ç›¸å°åŒ¯å…¥ï¼‰----
from ..embedding import safe_to_vector
from ..toolkits.memory_store import retrieve_memory_pack_v3, upsert_atoms_and_surfaces
from ..repositories.profile_repository import ProfileRepository

# redis èˆ‡å·¥å…·ï¼šæ³¨æ„ summarize_chunk_and_commit ä¾†è‡ª tools.py
from ..toolkits.redis_store import (
    fetch_all_history,
    get_summary,
    peek_remaining,
    cleanup_session_keys,
    set_state_if,
)
from ..toolkits.tools import (
    AlertCaseManagerTool,
    ModelGuardrailTool,
    SearchMilvusTool,
    summarize_chunk_and_commit,
)

OPENAI_MODEL = os.getenv("MODEL_NAME", "gpt-4o-mini")
EMBED_DIM = int(os.getenv("EMBED_DIM", 1536))

granddaughter_llm = LLM(
    model=os.getenv("MODEL_NAME", "gpt-4o-mini"),
    temperature=0.5,
)

guard_llm = LLM(
    model=os.getenv("MODEL_NAME", "gpt-4o-mini"),
    temperature=0,
)


# ========= å°å·¥å…· =========
def _now_ms() -> int:
    return int(time.time() * 1000)


def _stable_group_key(display_text: str) -> str:
    # ä»¥å±•ç¤ºæ–‡æœ¬ï¼ˆatom çš„å¯è®€æ•˜è¿°ï¼‰ç‚ºåŸºæº–åš hashï¼Œç¢ºä¿ atom/surface ç”¨åŒä¸€æŠŠ gk
    h = hashlib.sha1(display_text.lower().encode("utf-8")).hexdigest()[:32]
    return "auto:" + h


def _render_session_transcript(user_id: str, k: int = 9999) -> str:
    rounds = fetch_all_history(user_id) or []
    out = []
    for i, r in enumerate(rounds[-k:], 1):
        q = (r.get("input") or "").strip()
        a = (r.get("output") or "").strip()
        out.append(f"{i:02d}. ä½¿ç”¨è€…ï¼š{q}")
        out.append(f"   åŠ©æ‰‹ï¼š{a}")
    return "\n".join(out)


# ========= æª¢ç´¢æ¥é» (Prompt Building) =========
def build_prompt_from_redis(user_id: str, line_user_id: Optional[str] = None, k: int = 6, current_input: str = "") -> str:
    parts: List[str] = []
    
    # 0) å–ä½¿ç”¨è€…Profile
    try:
        profile = ProfileRepository().get_or_create_by_user_id(int(user_id), line_user_id=line_user_id)
        profile_data = {
            "personal_background": profile.profile_personal_background or {},
            "health_status": profile.profile_health_status or {},
            "life_events": profile.profile_life_events or {}
        }
        profile_data = {k: v for k, v in profile_data.items() if v}
        if profile_data:
            profile_str = json.dumps(profile_data, ensure_ascii=False, indent=2)
            parts.append(f"ğŸ‘¤ ä½¿ç”¨è€…ç•«åƒ (Profile):\n{profile_str}")
    except (ValueError, TypeError) as e:
        print(f"âš ï¸ [Build Prompt] user '{user_id}' è™•ç† Profile å¤±æ•—: {e}ï¼Œå°‡ä½¿ç”¨ç©ºçš„ Profileã€‚")
    
    # (1) é•·æœŸè¨˜æ†¶ï¼ˆåŸè©±å°å‘ï¼‰
    if current_input:
        qv = safe_to_vector(current_input)
        if qv:
            try:
                mem_pack = retrieve_memory_pack_v3(
                    user_id=user_id,
                    query_vec=qv,
                    topk_groups=5,
                    sim_thr=0.5,
                    tau_days=45,
                    include_raw_qa=False,
                )
                if mem_pack:
                    parts.append(mem_pack)
            except Exception as e:
                print(f"[memory v3 retrieval warn] {e}")

    # (2) æ­·å²æ‘˜è¦ï¼ˆå¯é¸ï¼‰
    try:
        summary_text, _ = get_summary(user_id)
        if summary_text:
            parts.append("ğŸ“Œ æ­·å²æ‘˜è¦ï¼š\n" + summary_text.strip())
    except Exception:
        pass

    # (3) è¿‘æœŸæœªæ‘˜è¦ç‰‡æ®µï¼ˆå¯é¸ï¼‰
    try:
        rounds = fetch_all_history(user_id) or []
        tail = rounds[-k:]
        if tail:
            lines = []
            for r in tail:
                q = (r.get("input") or "").strip()
                a = (r.get("output") or "").strip()
                lines.append(f"ä½¿ç”¨è€…ï¼š{q}")
                lines.append(f"åŠ©æ‰‹ï¼š{a}")
            parts.append("ğŸ•“ è¿‘æœŸå°è©±ï¼ˆæœªæ‘˜è¦ï¼‰ï¼š\n" + "\n".join(lines))
    except Exception:
        pass

    return "\n\n".join([p for p in parts if p.strip()]) or ""


# ========= Profile æ›´æ–°æ©Ÿåˆ¶ =========
PROFILER_AGENT_PROMPT_TEMPLATE = """
# ROLE
ä½ æ˜¯ã€Œè‰¾è‰ã€ï¼Œä¸€ä½å¿ƒæ€ç¸å¯†çš„å€‹æ¡ˆç®¡ç†å¸«ã€‚ä½ çš„å·¥ä½œæ˜¯æ ¹æ“šå‰›çµæŸçš„ä¸€æ®µå°è©±ä¸­**æç…‰å‡ºçš„çµæ§‹åŒ–äº‹å¯¦**ï¼Œä¾†æ›´æ–°ä½¿ç”¨è€…çš„é•·æœŸç•«åƒ (User Profile)ã€‚

# GOAL
ä½ çš„ç›®æ¨™æ˜¯åˆ†æã€Œæ–°çš„äº‹å¯¦æ¸…å–®ã€ï¼Œæ±ºå®šå¦‚ä½•ã€Œæ›´æ–°æ—¢æœ‰çš„ä½¿ç”¨è€…ç•«åƒã€ã€‚ä½ å¿…é ˆè¾¨åˆ¥å‡ºå…·æœ‰é•·æœŸåƒ¹å€¼çš„è³‡è¨Šï¼Œä¸¦ä»¥çµæ§‹åŒ–çš„ JSON æŒ‡ä»¤æ ¼å¼è¼¸å‡ºä½ çš„æ±ºç­–ã€‚

# CORE LOGIC & RULES
1.  **å°ˆæ³¨é•·æœŸåƒ¹å€¼**: åªæå–æ†å®šçš„ï¼ˆå¦‚å®¶äººå§“åï¼‰ã€é•·æœŸçš„ï¼ˆå¦‚æ…¢æ€§ç—…ï¼‰æˆ–æœªä¾†å¯è¿½è¹¤çš„ï¼ˆå¦‚ä¸‹æ¬¡å›è¨ºï¼‰è³‡è¨Šã€‚å¿½ç•¥çŸ­æš«çš„ã€ä¸€æ¬¡æ€§çš„å°è©±ç´°ç¯€ï¼ˆå¦‚ä»Šå¤©å¤©æ°£ã€åˆé¤åƒäº†ä»€éº¼ï¼‰ã€‚
2.  **èšç„¦é•·è¼©**ï¼šä¸å¯è¨˜éŒ„åŠ©ç†æä¾›çš„å»ºè­°ã€é¼“å‹µã€æé†’ï¼Œåªå¾ä½¿ç”¨è€…æ‰€èªªçš„å…§å®¹æå–è³‡è¨Šã€‚åªè¨˜éŒ„ä¸‰ç¨®é¡å‹çš„ä½¿ç”¨è€…è‡ªèº«è³‡è¨Šï¼šhealth_statusã€personal_backgroundã€life_eventsï¼›å°æ–¼å¥åº·ç‹€æ³ï¼Œåªèƒ½è¨˜éŒ„ä½¿ç”¨è€…è‡ªèº«æåˆ°çš„èº«é«”ç‹€æ³ï¼Œè‹¥åªæ˜¯è©¢å•å¥åº·çŸ¥è­˜ä½†æœªæåŠæœ¬èº«ç—‡ç‹€ï¼Œå‰‡ä¸è¨˜éŒ„ï¼›å°æ–¼å€‹äººèƒŒæ™¯ï¼Œåªèƒ½è¨˜éŒ„å®¶åº­ç‹€æ³ã€éå¾€è·æ¥­ã€èˆˆè¶£ç­‰æ†å®šäº‹å¯¦ï¼Œå°æ–¼èˆˆè¶£ï¼Œæ‡‰å¤§è‡´è¨˜éŒ„è€Œéè©³ç´°è¨˜éŒ„ï¼Œä¾‹å¦‚è¨˜éŒ„å–œæ­¡æŸäº›æ­Œæ‰‹ï¼Œä½†ä¸è¨˜éŒ„ç‰¹å®šæ­Œæ›²ã€‚å°æ–¼ç”Ÿæ´»äº‹ä»¶ï¼Œåªè¨˜éŒ„æ˜ç¢ºå°‡æœƒç™¼ç”Ÿçš„äº‹ä»¶ï¼Œä¾‹å¦‚æŸæ—¥å›è¨ºã€æŸæ—¥èšé¤ç­‰ï¼Œã€Œæƒ³å»ã€ã€ã€Œå¸Œæœ›å»ã€ç­‰éå¯¦éš›å®‰æ’äº‹ä»¶ä¸å¯è¨˜éŒ„ã€‚
3.  **å€åˆ†äº‹å¯¦èˆ‡ç–‘å•**: ä½ å¿…é ˆåš´æ ¼å€åˆ†ã€Œæ—¢å®šçš„äº‹å¯¦ã€èˆ‡ã€Œæš«æ™‚çš„ç–‘å•æˆ–ä¸ç¢ºå®šç‹€æ…‹ã€ã€‚
    * **å¯è¨˜éŒ„çš„äº‹å¯¦**: ä½¿ç”¨è€…æ˜ç¢ºé™³è¿°çš„èƒŒæ™¯è³‡è¨Šã€ç‹€æ…‹æˆ–äº‹ä»¶ã€‚ä¾‹å¦‚ï¼šã€Œé†«ç”Ÿå‘Šè¨´æˆ‘é€™å€‹è—¥è¦é£¯å¾Œåƒã€ã€ã€Œæˆ‘å°èŠ±ç”Ÿéæ•ã€ã€‚
    * **ä¸å¯è¨˜éŒ„çš„ç–‘å•**: å¦‚æœäº‹å¯¦æ¸…å–®è¡¨é”çš„æ˜¯ä¸€ç¨®ç–‘å•ã€å¿˜è¨˜æˆ–ä¸ç¢ºå®šï¼Œå‰‡ä¸èƒ½å°‡å…¶è¨˜éŒ„åˆ° Profile ä¸­ã€‚
3.  **åŸºæ–¼äº‹å¯¦**: ä½ çš„æ‰€æœ‰åˆ¤æ–·éƒ½å¿…é ˆåŸºæ–¼ã€Œæ–°çš„äº‹å¯¦æ¸…å–®ã€ä¸­çš„ `display_text` å’Œ `evidence`ï¼ˆåŸå§‹å¼•æ–‡ï¼‰ã€‚
4.  **æ–°å¢ (ADD)**: å¦‚æœæ–°æ‘˜è¦ä¸­å‡ºç¾äº†ç•«åƒè£¡æ²’æœ‰çš„ã€å…·é•·æœŸåƒ¹å€¼çš„é—œéµäº‹å¯¦ï¼Œä½ æ‡‰è©²æ–°å¢å®ƒã€‚
5.  **æ›´æ–° (UPDATE)**: å¦‚æœæ–°æ‘˜è¦æåŠäº†ç•«åƒä¸­å·²æœ‰çš„äº‹å¯¦ï¼Œä¸¦æä¾›äº†æ–°çš„è³‡è¨Šï¼ˆå¦‚ç—‡ç‹€å†æ¬¡å‡ºç¾ã€äº‹ä»¶æ—¥æœŸç¢ºå®šï¼‰ï¼Œä½ æ‡‰è©²æ›´æ–°å®ƒã€‚æ›´æ–°æ™‚å¿…é ˆç¢ºä¿ä¿ç•™ç„¡é ˆæ›´æ–°çš„è³‡è¨Šï¼ˆå¦‚é¦–æ¬¡æåŠæ—¥æœŸã€å³å°‡ç™¼ç”Ÿä¸”ä»å°‡ç™¼ç”Ÿçš„äº‹ä»¶ï¼‰ï¼Œä¸¦åªæ›´æ–°å¿…è¦çš„æ¬„ä½ï¼ˆå¦‚æœ€å¾ŒæåŠæ—¥æœŸã€ç‹€æ…‹ï¼‰ã€‚
6.  **ç§»é™¤ (REMOVE)**: å¦‚æœæ–°å°è©±æ˜ç¢ºæŒ‡å‡ºæŸå€‹äº‹å¯¦å·²çµæŸæˆ–å¤±æ•ˆï¼ˆå¦‚èšé¤å·²çµæŸã€ç—‡ç‹€å·²ç—Šç™’ï¼‰ï¼Œä½ æ‡‰è©²ç§»é™¤å®ƒã€‚è‹¥ç—‡ç‹€æœ€å¾ŒæåŠæ™‚é–“å·²è¶…éä¸€å€‹æœˆï¼Œå‰‡è¦–ç‚ºå·²çµæŸï¼Œæ‡‰è©²ç§»é™¤ã€‚
7.  **ç„¡è®Šå‹•å‰‡ç•™ç©º**: å¦‚æœæ–°æ‘˜è¦æ²’æœ‰æä¾›ä»»ä½•å€¼å¾—æ›´æ–°çš„é•·æœŸäº‹å¯¦ï¼Œè«‹å›å‚³ä¸€å€‹ç©ºçš„ JSON ç‰©ä»¶ `{{}}`ã€‚
8.  **çµ•å°æ™‚é–“åˆ¶**: ä½ çš„è¼¸å‡ºè‹¥åŒ…å«æ—¥æœŸï¼Œçš†**å¿…é ˆ**ä½¿ç”¨åƒè€ƒç•¶å‰æ—¥æœŸ (`NOW`)ï¼Œ**ç²¾ç¢ºåœ°**æ›ç®—ç‚º `YYYY-MM-DD` æ ¼å¼ã€‚ä¾‹å¦‚ï¼Œè‹¥ä»Šå¤©æ˜¯ 2025-08-21 (é€±å››)ï¼Œã€Œä¸‹é€±ä¸‰ã€æ‡‰æ›ç®—ç‚º `2025-08-27`ã€‚**åš´ç¦**ä½¿ç”¨ç›¸å°æ™‚é–“ã€‚

# OUTPUT FORMAT
ä½ ã€Œå¿…é ˆã€åš´æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¼¸å‡ºä¸€å€‹æ“ä½œæŒ‡ä»¤é›†ã€‚é€™è®“å¾Œç«¯ç³»çµ±å¯ä»¥å®‰å…¨åœ°åŸ·è¡Œä½ çš„æ±ºç­–ã€‚
{{
  "add": {{
    "personal_background": {{ "key": "value" }},
    "health_status": {{ "key": "value" }},
    "life_events": {{ "key": "value" }}
  }},
  "update": {{
    "personal_background": {{ "key": "new_value" }}
  }},
  "remove": ["health_status.some_key.0", "life_events.another_key"]
}}

---
# CONTEXT & IN-CONTEXT LEARNING EXAMPLES

**## æƒ…å¢ƒè¼¸å…¥ ##**
1.  **æ—¢æœ‰ä½¿ç”¨è€…ç•«åƒ (Existing Profile)**: 
    {{profile_data}}
2.  **æ–°çš„å°è©±æ‘˜è¦ (New Summary)**: 
    {{new_facts}}

---
**## å­¸ç¿’ç¯„ä¾‹ 1ï¼šæ–°å¢èˆ‡æ›´æ–° ##**
**ç•¶å‰æ™‚é–“**: 2025-08-14
* **æ—¢æœ‰ä½¿ç”¨è€…ç•«åƒ**:
    ```json
    {{
      "health_status": {{
        "recurring_symptoms": [
          {{"symptom_name": "å¤œå’³", "status": "ongoing", "first_mentioned": "2025-08-01", "last_mentioned": "2025-08-05"}}
        ]
      }}
    }}
    ```
* **æ–°çš„å°è©±æ‘˜è¦**:
    "ä½¿ç”¨è€…æƒ…ç·’ä¸éŒ¯ï¼Œæåˆ°å¥³å…’ç¾ç²ä¸‹é€±è¦å¸¶å­«å­å›ä¾†çœ‹ä»–ï¼Œæ„Ÿåˆ°å¾ˆæœŸå¾…ã€‚å¦å¤–ï¼Œä½¿ç”¨è€…å†æ¬¡æŠ±æ€¨äº†å¤œå’³çš„ç‹€æ³ï¼Œä½†æ„Ÿè¦ºæ¯”ä¸Šé€±å¥½ä¸€äº›ã€‚"
* **ä½ çš„æ€è€ƒ**: æ–°æ‘˜è¦ä¸­ï¼Œã€Œå¥³å…’ç¾ç²ã€å’Œã€Œå­«å­ã€æ˜¯æ–°çš„ã€é‡è¦çš„å®¶åº­æˆå“¡è³‡è¨Šï¼Œæ‡‰æ–°å¢ç‚ºpersonal_backgroundçš„å®¶åº­è³‡è¨Šã€‚å¥³å…’ä¸‹é€±å¸¶å­«å­ä¾†è¨ªï¼Œæ‡‰æ–°å¢ç‚ºupcoming_eventsï¼Œä¸¦å°‡"ä¸‹é€±"æ›ç®—ç‚º2025-08-17~2025-08-23ã€‚`å¤œå’³` æ˜¯æ—¢æœ‰ç—‡ç‹€ï¼Œæ‡‰æ›´æ–° `last_mentioned` æ—¥æœŸã€‚
* **ä½ çš„è¼¸å‡º**:
    ```json
    {{
      "add": {{
        "personal_background": {{
          "family": {{"daughter_name": "ç¾ç²", "has_grandchild": true}}
        }},
        "life_events": {{
          "upcoming_events": [
            {{"event_type": "family_visit", "description": "å¥³å…’ç¾ç²2025-08-17~2025-08-23å¸¶å­«å­ä¾†è¨ª", "event_date": "2025-08-17~2025-08-23"}}
          ]
      }}
      }},
      "update": {{
        "health_status": {{
          "recurring_symptoms": [
            {{"symptom_name": "å¤œå’³", "status": "ongoing", "first_mentioned": "2025-08-01", "last_mentioned": "2025-08-14"}}
          ]
        }}
      }},
      "remove": []
    }}
    ```

---
**## å­¸ç¿’ç¯„ä¾‹ 2ï¼šäº‹ä»¶çµæŸèˆ‡ç‹€æ…‹è®Šæ›´ ##**
**ç•¶å‰æ™‚é–“**: 2025-08-24
* **æ—¢æœ‰ä½¿ç”¨è€…ç•«åƒ**:
    ```json
    {{
      "life_events": {{
        "upcoming_events": [
          {{"event_type": "family_visit", "description": "å¥³å…’ç¾ç²2025-08-17~2025-08-23å¸¶å­«å­ä¾†è¨ª", "event_date": "2025-08-17~2025-08-23"}}
        ]
      }},
      "health_status": {{
        "recurring_symptoms": [
          {{"symptom_name": "å¤œå’³", "status": "ongoing", "first_mentioned": "2025-08-01", "last_mentioned": "2025-08-14"}}
        ]
      }}
    }}
    ```
* **æ–°çš„å°è©±æ‘˜è¦**:
    "ä½¿ç”¨è€…åˆ†äº«äº†é€±æœ«å’Œå¥³å…’å­«å­åœ˜èšçš„æ„‰å¿«æ™‚å…‰ï¼Œå¿ƒæƒ…éå¸¸å¥½ã€‚ä»–é‚„æåˆ°ï¼Œé€™å¹¾å¤©ç¡å¾—å¾ˆå¥½ï¼Œå¤œå’³çš„ç‹€æ³å¹¾ä¹æ²’æœ‰äº†ã€‚"
* **ä½ çš„æ€è€ƒ**: ã€Œå¥³å…’ä¾†è¨ªã€é€™å€‹æœªä¾†äº‹ä»¶å·²ç¶“ç™¼ç”Ÿï¼Œæ‡‰ç§»é™¤ã€‚`å¤œå’³` ç‹€æ³å·²æ”¹å–„ï¼Œæ‡‰æ›´æ–°å…¶ç‹€æ…‹ã€‚
* **ä½ çš„è¼¸å‡º**:
    ```json
    {{
      "add": {{}},
      "update": {{
        "health_status": {{
          "recurring_symptoms": [
            {{"symptom_name": "å¤œå’³", "status": "resolved", "first_mentioned": "2025-08-01", "last_mentioned": "2025-08-25"}}
          ]
        }}
      }},
      "remove": ["life_events.upcoming_events"]
    }}
    ```

---
**## ä½ çš„ä»»å‹™é–‹å§‹ ##**

ä½ çš„ä»»å‹™:
æ¯”è¼ƒã€Œæ—¢æœ‰ç•«åƒã€èˆ‡ã€Œæ–°äº‹å¯¦æ¸…å–®ã€ï¼Œç”Ÿæˆä¸Šè¿°æ ¼å¼çš„ JSON æ›´æ–°æŒ‡ä»¤ã€‚

**ç•¶å‰æ™‚é–“**: 
`{now}`

**æ—¢æœ‰ä½¿ç”¨è€…ç•«åƒ**: 
`{profile_data}`

**æœ¬æ¬¡å°è©±æç…‰å‡ºçš„æ–°äº‹å¯¦æ¸…å–®**: 
`{new_facts}`

**ä½ çš„è¼¸å‡º**:
```json
"""

def create_profiler_agent() -> Agent:
    """å»ºç«‹å°ˆé–€ç”¨ä¾†æ›´æ–° Profile çš„ Agent ç‰©ä»¶"""
    return Agent(
        role="å€‹æ¡ˆç®¡ç†å¸«",
        goal="æ ¹æ“šæ–°çš„å°è©±ï¼Œæ±ºå®šå¦‚ä½•æ›´æ–°æ—¢æœ‰çš„ä½¿ç”¨è€…ç•«åƒï¼Œä¸¦ä»¥çµæ§‹åŒ–çš„ JSON æŒ‡ä»¤æ ¼å¼è¼¸å‡ºæ±ºç­–ã€‚",
        backstory="ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œã€å¿ƒæ€ç¸å¯†çš„å€‹æ¡ˆç®¡ç†å¸«ï¼Œå°ˆæ³¨æ–¼å¾å°è©±ä¸­æå–å…·æœ‰é•·æœŸåƒ¹å€¼çš„è³‡è¨Šä¾†ç¶­è­·ç²¾ç°¡ã€æº–ç¢ºçš„ä½¿ç”¨è€…ç•«åƒã€‚",
        llm=ChatOpenAI(model=os.getenv("MODEL_NAME", "gpt-4o-mini"), temperature=0.1), # ä½¿ç”¨ä½æº«ä»¥ç¢ºä¿è¼¸å‡ºç©©å®š
        memory=False,
        verbose=False,
        allow_delegation=False
    )


def run_profiler_update(user_id: str, facts: List[Dict[str, Any]]):
    """
    åœ¨æç…‰å‡º facts å¾Œï¼Œè§¸ç™¼ Profiler Agent ä¾†æ›´æ–°ä½¿ç”¨è€…ç•«åƒã€‚
    """
    if not facts:
        print(f"[Profiler] äº‹å¯¦æ¸…å–®ç‚ºç©ºï¼Œè·³éç‚º user {user_id} æ›´æ–° Profileã€‚")
        return

    print(f"[Profiler] é–‹å§‹ç‚º user {user_id} æ›´æ–° Profile...")
    repo = ProfileRepository()
    
    # 1. ç²å–èˆŠ Profile
    try:
        user_id_int = int(user_id)
        old_profile = repo.read_profile_as_dict(user_id_int)
        old_profile_str = json.dumps(old_profile, ensure_ascii=False, indent=2) if any(old_profile.values()) else "{}"
    except (ValueError, TypeError) as e:
        print(f"âŒ [Profiler] ç„¡æ•ˆçš„ user_id '{user_id}'ï¼Œç„¡æ³•æ›´æ–° Profile: {e}")
        return
    
    # 2. å»ºç«‹ Profiler Agent ä¸¦åŸ·è¡Œä»»å‹™
    profiler_agent = create_profiler_agent()
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    facts_str = json.dumps(facts, ensure_ascii=False, indent=2)

    full_prompt = PROFILER_AGENT_PROMPT_TEMPLATE.format(
        now=now_str,
        profile_data=old_profile_str,
        new_facts=facts_str
    )
    
    profiler_task = Task(
        description=full_prompt,
        agent=profiler_agent,
        expected_output="ä¸€å€‹åŒ…å« 'add', 'update', 'remove' æŒ‡ä»¤çš„ JSON ç‰©ä»¶ã€‚"
    )
    
    crew = Crew(
        agents=[profiler_agent],
        tasks=[profiler_task],
        process=Process.sequential,
        verbose=False
    )
    
    crew_output = crew.kickoff()
    update_commands_str = crew_output.raw if crew_output else ""
    
    # å°å‡º LLM åŸå§‹è¼¸å‡º
    print(f"--- [Profiler Raw Output for user {user_id}] ---")
    print(update_commands_str)
    print("------------------------------------------")

    # 3. è§£ææŒ‡ä»¤ä¸¦æ›´æ–°è³‡æ–™åº«
    try:
        start_index = update_commands_str.find('{')
        end_index = update_commands_str.rfind('}') + 1
        if start_index == -1 or end_index == 0:
            print(f"[Profiler] LLM è¼¸å‡ºä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON ç‰©ä»¶ï¼Œè·³éæ›´æ–°ã€‚åŸå§‹è¼¸å‡º: {update_commands_str}")
            return
        
        json_str = update_commands_str[start_index:end_index]
        update_commands = json.loads(json_str)

        if update_commands and any(update_commands.values()):
            repo.update_profile_facts(int(user_id), update_commands)
        else:
            print(f"[Profiler] LLM ç‚º user {user_id} å›å‚³äº†ç©ºçš„æ›´æ–°æŒ‡ä»¤ï¼Œç„¡éœ€æ›´æ–°ã€‚")
            
    except json.JSONDecodeError as e:
        print(f"âŒ [Profiler] è§£æ LLM è¼¸å‡ºçš„ JSON å¤±æ•—: {e}")
        print(f"åŸå§‹è¼¸å‡º: {update_commands_str}")
    except Exception as e:
        print(f"âŒ [Profiler] æ›´æ–° Profile éç¨‹ä¸­ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")


# ========= Finalizeï¼šè¨˜æ†¶è’¸é¤¾ =========
_DISTILL_SYS = """
ä½ æ˜¯ã€Œè¨˜æ†¶è’¸é¤¾å™¨ã€ã€‚è«‹å¾æœ¬è¼ªå°è©±ä¸­ï¼ŒåªæŠ½å–ã€å¯é•·æœŸé‡ç”¨çš„æ—¢å®šäº‹å¯¦ã€ï¼Œä¸¦ç‚ºæ¯ä¸€é …æŒ‡å®šä¿å­˜æœŸé™ï¼ˆTTLï¼‰ã€‚
æŠ½å–è¦å‰‡ï¼ˆå‹™å¿…éµå®ˆï¼‰ï¼š
- åªæ”¶ï¼šå€‹äººèƒŒæ™¯è³‡è¨Šï¼ˆå¦‚å®¶åº­ã€ç¶“æ­·ã€å–œå¥½ï¼‰ã€éæ•å²ã€å›ºå®šåå¥½ã€é†«å›‘/ç”¨è—¥ï¼ˆç¾è¡Œï¼‰ã€å›ºå®šè¡Œç¨‹/æé†’ã€è¯çµ¡äººã€æ…¢æ€§ç—…å²ã€é•·æœŸé™åˆ¶/ç¦å¿Œã€‚
- ä¸æ”¶ï¼šå¯’æš„ã€ä¸€æ¬¡æ€§äº‹ä»¶ã€çŸ­æœŸç—‡ç‹€ã€çŒœæ¸¬ã€æ¨¡å‹æ„è¦‹ã€‚
- æ¯é …æä¾› 200 å­—å…§å¯è®€æ•˜è¿°ï¼ˆdisplay_textï¼‰ï¼Œä¸å¾—æ·»åŠ æœªå‡ºç¾çš„æ¨æ¸¬ã€‚
- æ¯é …é™„ 1â€“3 å¥ã€evidence åŸè©±ã€‘ï¼ˆé€å­—å¼•ç”¨ä½¿ç”¨è€…æˆ–åŠ©æ‰‹è©±èªï¼‰ï¼Œä¹‹å¾Œå°‡ä»¥æ­¤åšå‘é‡æª¢ç´¢ã€‚
- TTL è¦å‰‡ï¼š
  info/allergy/æ…¢æ€§ç—…/è¯çµ¡äººï¼šttl_days=0ï¼ˆæ°¸ä¹…ï¼‰
  é†«å›‘/ç”¨è—¥ï¼šttl_days=180
  å›ºå®šåå¥½ï¼šttl_days=365
  å›ºå®šè¡Œç¨‹/æé†’ï¼šttl_days=90
  å…¶ä»–é•·æœŸé™åˆ¶/ç¦å¿Œï¼šttl_days=365
- è‹¥ç„¡ç¬¦åˆï¼Œè¼¸å‡ºç©ºé™£åˆ— []ã€‚
è¼¸å‡º JSON é™£åˆ—ï¼Œå…ƒç´ æ ¼å¼ï¼š
{
  "type": "info|allergy|preference|doctor_order|schedule|reminder|contact|condition|constraint|note",
  "display_text": "<200å­—å…§å¯è®€æ•˜è¿°>",
  "evidence": ["<åŸè©±1>", "<åŸè©±2>"],  // æœ€å¤š3å¥
  "ttl_days": 0|90|180|365
}
""".strip()


def _distill_facts(user_id: str) -> List[Dict[str, Any]]:
    transcript = _render_session_transcript(user_id)
    if not transcript.strip():
        return []
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    res = client.chat.completions.create(
        model=OPENAI_MODEL,
        temperature=0.2,
        max_tokens=900,
        messages=[
            {"role": "system", "content": _DISTILL_SYS},
            {
                "role": "user",
                "content": f"ä½¿ç”¨è€…æœ¬è¼ªå°è©±å¦‚ä¸‹ï¼ˆé€å­—ï¼‰ï¼š\n<<<\n{transcript}\n>>>",
            },
        ],
    )
    raw = (res.choices[0].message.content or "").strip()
    print(f"\n--- [è¨˜æ†¶è’¸é¤¾LLMåŸå§‹è¼¸å‡º: user {user_id}] ---")
    print(raw)
    print("----------------------------------------------------\n")

    # æ¸…æ‰ ```json å€å¡Šç¬¦è™Ÿ
    if raw.startswith("```"):
        lines = [ln for ln in raw.splitlines() if not ln.strip().startswith("```")]
        raw = "\n".join(lines).strip()
    lb, rb = raw.find("["), raw.rfind("]")
    if lb == -1 or rb == -1 or rb <= lb:
        return []
    try:
        arr = json.loads(raw[lb : rb + 1])
        return arr if isinstance(arr, list) else [arr]
    except Exception:
        return []


def _ttl_days_to_expire_at(ttl_days: int) -> int:
    if not ttl_days or int(ttl_days) == 0:
        return 0
    return _now_ms() + int(ttl_days) * 86400 * 1000


def finalize_session(user_id: str) -> None:
    """
    æœƒè©±æ”¶å°¾ï¼š
    1) ï¼ˆå¯é¸ï¼‰è£œæ‘˜è¦ï¼ˆç´”ç‚ºé™æœ¬ï¼Œä¸å½±éŸ¿ LTMï¼‰
    2) LLM è’¸é¤¾ â†’ æ—¢å®šäº‹å¯¦ + evidence(åŸè©±) + ttl_days
    3) å¯«å…¥ Milvusï¼š
       - atomï¼štext=display_textï¼›embedding=0 å‘é‡ï¼›expire_at=ç”± ttl_days æ±ºå®š
       - surfaceï¼štext=åŸè©±ï¼›embedding=E(åŸè©±)ï¼›expire_at åŒä¸Š
    4) æ ¹æ“šè’¸é¤¾å‡ºçš„äº‹å¯¦æ›´æ–° Profile
    5) æ¸…ç† Redis session
    """
    # 1) æ‘˜è¦ï¼ˆå¯è¨»è§£æ‰ï¼‰
    try:
        set_state_if(user_id, expect="ACTIVE", to="FINALIZING")
        start, remaining = peek_remaining(user_id)
        if remaining:
            summarize_chunk_and_commit(
                user_id, start_round=start, history_chunk=remaining
            )
    except Exception as e:
        print(f"[finalize summary warn] {e}")

    # 2) è¨˜æ†¶è’¸é¤¾
    facts = _distill_facts(user_id)

    # 3) å…¥åº«
    to_upsert = []
    session_id = f"sess:{int(time.time())}"
    for f in facts:
        display = (f.get("display_text") or "").strip()
        if not display:
            continue
        ttl_days = int(f.get("ttl_days", 365))
        expire_at = _ttl_days_to_expire_at(ttl_days)
        gk = _stable_group_key(display)  # â˜… ç”¢ç”Ÿç©©å®š group_key

        # atomï¼ˆå±•ç¤ºç”¨ï¼‰
        to_upsert.append(
            {
                "type": "atom",
                "group_key": gk,
                "text": display[:4000],
                "importance": (
                    4
                    if f.get("type")
                    in ("allergy", "doctor_order", "contact", "condition")
                    else 3
                ),
                "confidence": 0.9,
                "times_seen": 1,
                "status": "active",
                "source_session_id": session_id,
                "expire_at": expire_at,
                "embedding": [0.0] * EMBED_DIM,  # å ä½ï¼Œä¸åƒèˆ‡æª¢ç´¢
            }
        )

        # surfacesï¼ˆæª¢ç´¢ä¸»åŠ›ï¼‰ï¼šå° evidence åŸå¥åš embedding
        for ev in (f.get("evidence") or [])[:3]:
            ev_txt = (ev or "").strip()
            if not ev_txt:
                continue
            vec = safe_to_vector(ev_txt) or []
            if not vec:
                continue
            to_upsert.append(
                {
                    "type": "surface",
                    "group_key": gk,
                    "text": ev_txt[:4000],
                    "importance": 2,
                    "confidence": 0.95,
                    "times_seen": 1,
                    "status": "active",
                    "source_session_id": session_id,
                    "expire_at": expire_at,
                    "embedding": vec,
                }
            )

    if to_upsert:
        try:
            upsert_atoms_and_surfaces(user_id, to_upsert)
            print(f"âœ… finalizeï¼šå·²å¯«å…¥é•·æœŸè¨˜æ†¶ {len(to_upsert)} ç­†ï¼ˆatom/surfaceï¼‰")
        except Exception as e:
            print(f"[finalize upsert error] {e}")
    else:
        print("â„¹ï¸ finalizeï¼šæœ¬è¼ªæ²’æœ‰å¯é•·æœŸä¿å­˜çš„äº‹å¯¦")

    # 4) æ›´æ–° Profile
    # ä½¿ç”¨ç¬¬ 2 æ­¥ç”¢ç”Ÿçš„ facts ä¾†æ›´æ–° Profile
    run_profiler_update(user_id, facts)

    # 5) æ¸…ç† session
    try:
        cleanup_session_keys(user_id)
    except Exception as e:
        print(f"[finalize purge warn] {e}")


# ========= CrewAI ä»£ç†å·¥å» ï¼ˆä¾› chat_pipeline åŒ¯å…¥ï¼‰=========
def create_guardrail_agent() -> Agent:
    return Agent(
        role="Guardrail",
        goal="åˆ¤æ–·æ˜¯å¦éœ€è¦æ””æˆªä½¿ç”¨è€…è¼¸å…¥ï¼ˆå®‰å…¨/æ³•å¾‹/é†«ç™‚ç­‰é«˜é¢¨éšªï¼‰",
        backstory="åš´è¬¹çš„å®‰å…¨å¯©æŸ¥å™¨",
        tools=[ModelGuardrailTool()],
        verbose=False,
        allow_delegation=False,
        llm=guard_llm,
        memory=False,
    )


def create_health_companion(user_id: str) -> Agent:
    return Agent(
        role="National Granddaughter Ally",
        goal="æº«æš–é™ªä¼´ä¸¦çµ¦ä¸€è¡Œå›è¦†ï¼›å·¥å…·åƒ…åœ¨ç¬¦åˆç•¶è¼ªè¦å‰‡æ™‚ä½¿ç”¨ï¼Œé¿å…ä¸å¿…è¦çš„æŸ¥è©¢èˆ‡é€šå ±ã€‚",
        backstory=f"é™ªä¼´ä½¿ç”¨è€… {user_id} çš„æº«æš–å­«å¥³",
        tools=[
            SearchMilvusTool(),
            AlertCaseManagerTool(),
        ],  # ç·Šæ€¥æ™‚æœƒè¢«ä»»å‹™ prompt è¦æ±‚è§¸ç™¼
        verbose=False,
        allow_delegation=False,
        llm=granddaughter_llm,
        memory=False,
        max_iterations=1,
    )
