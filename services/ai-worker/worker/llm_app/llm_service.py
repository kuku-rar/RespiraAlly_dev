import importlib
import os
import sys
from typing import Any, Dict

# ç¦ç”¨ CrewAI é™æ¸¬åŠŸèƒ½ï¼ˆé¿å…é€£æ¥éŒ¯èª¤ï¼‰
os.environ["OTEL_SDK_DISABLED"] = "true"
os.environ["CREWAI_TELEMETRY_OPT_OUT"] = "true"

# å…¼å®¹ã€Œæ¨¡çµ„æ–¹å¼ã€èˆ‡ã€Œç›´æ¥è…³æœ¬ã€å…©ç¨®åŸ·è¡Œæƒ…å¢ƒ
try:
    from .chat_pipeline import AgentManager, handle_user_message
    from .HealthBot.agent import finalize_session
except Exception:
    # è‹¥ä»¥è…³æœ¬æ¨¡å¼åŸ·è¡Œï¼ˆç„¡å°åŒ…ä¸Šä¸‹æ–‡ï¼‰ï¼ŒæŠŠ /app/worker åŠ é€² sys.path
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from llm_app.chat_pipeline import AgentManager, handle_user_message
    from llm_app.HealthBot.agent import finalize_session


class LLMService:
    """LLM å¾®æœå‹™æ¥å£ï¼Œè² è²¬ Milvus é€£æ¥å’Œå¤šç”¨æˆ¶æœƒè©±ç®¡ç†"""

    def __init__(self) -> None:
        print("ğŸš€ Initializing a new LLMService instance...")
        self.agent_manager = AgentManager()
        self._milvus_connected = False
        self._ensure_milvus_connection()

    def _ensure_milvus_connection(self):
        """ç¢ºä¿ Milvus é€£æ¥ï¼ˆé•·æœŸè¨˜æ†¶åŠŸèƒ½éœ€è¦ï¼‰"""
        if self._milvus_connected:
            return

        try:
            from pymilvus import connections

            milvus_uri = os.getenv("MILVUS_URI", "http://localhost:19530")
            connections.connect(alias="default", uri=milvus_uri)
            self._milvus_connected = True
            print("âœ… Milvus é€£æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  Milvus é€£æ¥å¤±æ•—: {e}")
            print("é•·æœŸè¨˜æ†¶åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")


    def generate_response(self, task_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå›æ‡‰ï¼ˆåŒ…å«å®Œæ•´é•·æœŸè¿½è¹¤åŠŸèƒ½å’Œç¨ç«‹ç”¨æˆ¶æœƒè©±ç®¡ç†ï¼‰

        æœŸå¾…çš„ task_data æ¬„ä½å°æ‡‰ï¼š
        - patient_id -> å°æ‡‰ Final çš„ user_id
        - text -> å°æ‡‰ Final çš„ queryï¼ˆå¯é¸ï¼‰
        - object_name -> å°æ‡‰ Final çš„ audio_idï¼ˆå¯é¸ï¼‰
        - line_user_id -> å°æ‡‰ LINE çš„ä½¿ç”¨è€… ID
        """
        if not isinstance(task_data, dict):
            return "åƒæ•¸æ ¼å¼éŒ¯èª¤"

        user_id = str(
            task_data.get("patient_id") or task_data.get("user_id") or "unknown_user"
        )
        line_user_id = task_data.get("line_user_id")
        query = str(task_data.get("text") or "").strip()
        audio_id = None
        # å„ªå…ˆä½¿ç”¨ object_name ç•¶ audio_idï¼›è‹¥æ²’æœ‰ä¸”ç‚ºç´”æ–‡å­—å‰‡ç”±æµç¨‹è‡ªå‹•ä»¥ hash ç”¢ç”Ÿ
        if task_data.get("object_name"):
            audio_id = str(task_data.get("object_name"))

        if not query and not audio_id:
            return "ç¼ºå°‘å¿…è¦è¼¸å…¥ï¼ˆtext æˆ– object_name è‡³å°‘ä¸€é …ï¼‰"

        if not line_user_id:
            print(f"âš ï¸ è­¦å‘Šï¼šä¾†è‡ª user_id {user_id} çš„è«‹æ±‚ç¼ºå°‘ line_user_idï¼ŒProfile åŠŸèƒ½å°‡å—é™ã€‚")


        try:
            # ç¢ºä¿ Milvus é€£æ¥ï¼ˆé•·æœŸè¨˜æ†¶åŠŸèƒ½ï¼‰
            self._ensure_milvus_connection()

            # Session çš„åˆ·æ–°æ”¹ä»¥ handle_user_message -> log_session -> append_round å®Œæˆ
            response_text = handle_user_message(
                agent_manager=self.agent_manager,
                user_id=user_id,
                line_user_id=line_user_id,
                query=query,
                audio_id=audio_id,
                is_final=True,
            )
            return response_text
        except Exception as e:
            print(f"[LLMService] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return "æŠ±æ­‰ï¼Œç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚"

    def finalize_user_session_now(self, user_id: str):
        """
        ä¾›æ’ç¨‹ä»»å‹™å‘¼å«ï¼Œç«‹å³åŸ·è¡ŒæŒ‡å®šç”¨æˆ¶çš„ Session çµæŸæµç¨‹ã€‚
        """
        print(f"â³ åŸ·è¡Œé–’ç½®å°è©±çš„æ”¶å°¾æµç¨‹ï¼šuser_id = {user_id}")
        try:
            # æ•´ç†é•·æœŸè¨˜æ†¶ä¸¦é‡‹æ”¾ Agent
            finalize_session(user_id)
            self.agent_manager.release_health_agent(user_id)
            print(f"âœ… å°è©±æ”¶å°¾å®Œæˆï¼šuser {user_id}")
        except Exception as e:
            print(f"âš ï¸ å°è©±æ”¶å°¾å‡ºéŒ¯ï¼šuser {user_id}: {e}")
            # å³ä½¿å¤±æ•—ï¼Œä¹Ÿç¢ºä¿ agent è¢«é‡‹æ”¾
            self.agent_manager.release_health_agent(user_id)

llm_service_instance = LLMService()

def run_interactive_test():
    """äº’å‹•å¼æ¸¬è©¦ - å›ºå®šç”¨æˆ¶ test_user1ï¼Œæ¸¬è©¦ 5 åˆ†é˜é‡‹æ”¾åŠŸèƒ½"""
    print("ğŸ¥ Beloved Grandson LLM Service - äº’å‹•æ¸¬è©¦æ¨¡å¼")
    print("=" * 60)
    print("ğŸ’¡ åŠŸèƒ½èªªæ˜ï¼š")
    print("  - å›ºå®šç”¨æˆ¶ï¼štest_user1")
    print("  - æœ‰è¼¸å…¥æ™‚é‡æ–°é–‹å§‹è¨ˆç®— 5 åˆ†é˜")
    print("  - 5 åˆ†é˜ç„¡æ´»å‹•å¾Œè‡ªå‹•é‡‹æ”¾ Agent")
    print("  - ä½¿ç”¨ Ctrl+C é€€å‡º")
    print("=" * 60)

    # åˆå§‹åŒ–æœå‹™
    llm_service = LLMService()
    user_id = "test_user1"

    print("\nğŸ“‹ ä½¿ç”¨èªªæ˜ï¼š")
    print("  - ç›´æ¥è¼¸å…¥æ‚¨çš„è¨Šæ¯")
    print("  - æŒ‰ Ctrl+C é€€å‡ºæ¸¬è©¦")
    print("=" * 60)

    while True:
        try:
            message = input("\nè«‹è¼¸å…¥æ‚¨çš„è¨Šæ¯: ").strip()

            if not message:
                continue

            # æ§‹å»º task_data
            task_data = {"patient_id": user_id, "text": message}

            print(f"\nğŸ—£ï¸  è¼¸å…¥ï¼š{message}")
            response = llm_service_instance.generate_response(task_data)
            print(f"ğŸ¤– AI å›æ‡‰ï¼š{response}")

        except KeyboardInterrupt:
            print("\n\nğŸ”š æ”¶åˆ° Ctrl+C ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨æ¸…ç†...")
            print("ğŸ‘‹ å†è¦‹ï¼")
            break
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    try:
        from dotenv import load_dotenv

        load_dotenv()
    except Exception:
        pass

    # å»ºè­°ä»¥æ¨¡çµ„æ¨¡å¼åŸ·è¡Œï¼Œç¢ºä¿å°åŒ…è·¯å¾‘æ­£ç¢ºï¼š
    #   python -m llm_app.llm_service
    run_interactive_test()
    # æ¸¬è©¦ LLMService
    # 0. .env.example æ”¹æˆ .env ï¼Œå¯ä»¥ä¸åšä»»ä½•è¨­å®š
    # 1. å•Ÿå‹•ai-workerå’Œç›¸é—œçš„å®¹å™¨
    # docker-compose -f docker-compose.dev.yml up -d --build ai-worker

    # 2. åŸ·è¡Œæ¸¬è©¦è…³æœ¬
    # docker-compose -f docker-compose.dev.yml exec ai-worker python worker/llm_app/llm_service.py

    #! task_dataï¼š LLM RAG éœ€è¦ä»€éº¼å…§å®¹ï¼Œè«‹æ‰¾åšå¾Œç«¯çš„äººè¦ï¼Œå¾Œç«¯æœƒè™•ç†ä¸¦å°‡è³‡æ–™æ”¾ç½®åœ¨task_dataè£¡é¢
